{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgiiqBqVx+RLVhyB8xg4GR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikesplore/Face-Match/blob/main/identity_verification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup and Installation**\n",
        "\n",
        "face_recognition: For face detection and recognition\n",
        "\n",
        "opencv-python: For image processing\n",
        "\n",
        "easyocr: For extracting text from ID cards\n",
        "\n",
        "dlib: Required by face_recognition for face landmark detection\n",
        "\n",
        "Pillow: For image handling"
      ],
      "metadata": {
        "id": "tkXCbpWxrRQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install face_recognition opencv-python easyocr dlib numpy Pillow matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3EKEgUVrmFx",
        "outputId": "651dadf9-8be7-4e53-b97d-c6d20e4f34c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: easyocr in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: dlib in /usr/local/lib/python3.12/dist-packages (19.24.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.12/dist-packages (from face_recognition) (8.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.24.0+cpu)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Requirement already satisfied: python-bidi in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.6.7)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.2)\n",
            "Requirement already satisfied: pyclipper in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.4.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.13.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**\n",
        "Import all necessary libraries for:\n",
        "\n",
        "Image processing (OpenCV, PIL)\n",
        "\n",
        "Face recognition (face_recognition)\n",
        "\n",
        "Text extraction (easyocr)\n",
        "\n",
        "Data handling (numpy, json)\n",
        "\n",
        "File operations (os, google.colab)"
      ],
      "metadata": {
        "id": "8-YVDKm-rrtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import easyocr\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "from PIL import Image, ImageEnhance # Added ImageEnhance\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IOJZD442rzfj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Upload Images Function**\n",
        "\n",
        "Since Colab can't access your webcam directly, we'll upload images:\n",
        "\n",
        "Selfie image (simulating live camera capture)\n",
        "\n",
        "ID front image\n",
        "\n",
        "ID back image (optional)\n",
        "The uploaded files are saved to Colab's temporary storage."
      ],
      "metadata": {
        "id": "FaE51oAfsEJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_id_images():\n",
        "    \"\"\"Reads pre-uploaded selfie and ID images for verification\"\"\"\n",
        "    print(\"üì± LOOKING FOR YOUR IMAGES (Please ensure they are named selfie.jpg, id_front.jpg, and optionally id_back.jpg)\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    selfie_filename = 'selfie.jpg'\n",
        "    id_front_filename = 'id_front.jpg'\n",
        "    id_back_filename = 'id_back.jpg'\n",
        "\n",
        "    if not os.path.exists(selfie_filename):\n",
        "        print(f\"‚ùå Error: '{selfie_filename}' not found. Please upload and rename your selfie image.\")\n",
        "        return None, None, None\n",
        "    print(f\"‚úì Found: {selfie_filename}\")\n",
        "\n",
        "    if not os.path.exists(id_front_filename):\n",
        "        print(f\"‚ùå Error: '{id_front_filename}' not found. Please upload and rename your ID front image.\")\n",
        "        return None, None, None\n",
        "    print(f\"‚úì Found: {id_front_filename}\")\n",
        "\n",
        "    if os.path.exists(id_back_filename):\n",
        "        print(f\"‚úì Found: {id_back_filename}\")\n",
        "    else:\n",
        "        id_back_filename = None\n",
        "        print(\"‚úì Skipped ID back image (file not found)\")\n",
        "\n",
        "    return selfie_filename, id_front_filename, id_back_filename\n",
        "\n",
        "# Test upload function\n",
        "# selfie_file, id_front_file, id_back_file = upload_id_images()"
      ],
      "metadata": {
        "id": "2MYpoCrVsQuT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Detection Function**\n",
        "\n",
        "Face detection process:\n",
        "\n",
        "Load image using face_recognition.load_image_file()\n",
        "\n",
        "Find all faces using HOG (Histogram of Oriented Gradients) method\n",
        "\n",
        "Extract face encodings (128-dimensional vector = face \"fingerprint\")\n",
        "\n",
        "Return encoding, location, and cropped face image\n",
        "Each person's face encoding is unique and mathematically comparable."
      ],
      "metadata": {
        "id": "QN0Q50tPs0X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fix_image_orientation(image_path):\n",
        "    \"\"\"\n",
        "    Checks image orientation and rotates if necessary. Returns path to fixed image.\n",
        "    If no rotation needed, returns original path.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        # Get EXIF orientation tag\n",
        "        exif = img._getexif()\n",
        "        orientation = exif.get(0x112)\n",
        "\n",
        "        if orientation == 3: # Rotated 180\n",
        "            img = img.rotate(180, expand=True)\n",
        "        elif orientation == 6: # Rotated 90 CW\n",
        "            img = img.rotate(270, expand=True)\n",
        "        elif orientation == 8: # Rotated 90 CCW\n",
        "            img = img.rotate(90, expand=True)\n",
        "\n",
        "        if orientation in [3, 6, 8]:\n",
        "            fixed_path = image_path.replace('.jpg', '_fixed.jpg')\n",
        "            img.save(fixed_path)\n",
        "            print(f\"‚úì Fixed orientation for {image_path}, saved to {fixed_path}\")\n",
        "            return fixed_path\n",
        "        else:\n",
        "            return image_path\n",
        "\n",
        "    except (AttributeError, KeyError, IndexError, TypeError) as e:\n",
        "        # No EXIF data, or other error, assume correct orientation\n",
        "        # print(f\"Warning: Could not get EXIF orientation for {image_path}: {e}\")\n",
        "        return image_path\n",
        "\n",
        "def detect_face_in_image(image_path):\n",
        "    \"\"\"\n",
        "    Detect and extract face from an image using multiple robust methods.\n",
        "    Returns: (encoding, location, face_image) or (None, None, None)\n",
        "    \"\"\"\n",
        "    print(f\"üîÑ Attempting robust face detection for {image_path}...\")\n",
        "\n",
        "    # Step 1: Fix image orientation first\n",
        "    processed_image_path = fix_image_orientation(image_path)\n",
        "\n",
        "    # Load image (potentially fixed orientation)\n",
        "    image = face_recognition.load_image_file(processed_image_path)\n",
        "\n",
        "    best_face_location = None\n",
        "    best_face_encoding = None\n",
        "\n",
        "    # Define multiple detection strategies\n",
        "    detection_strategies = [\n",
        "        {\"model\": \"hog\", \"upsample\": 2, \"name\": \"HOG (upsample 2x)\"},\n",
        "        {\"model\": \"cnn\", \"upsample\": 1, \"name\": \"CNN (no upsample)\"},\n",
        "        {\"model\": \"cnn\", \"upsample\": 2, \"name\": \"CNN (upsample 2x)\"},\n",
        "        {\"model\": \"hog\", \"upsample\": 1, \"name\": \"HOG (no upsample)\"} # Less aggressive for speed after others failed\n",
        "    ]\n",
        "\n",
        "    # Try each strategy\n",
        "    for strategy in detection_strategies:\n",
        "        model_name = strategy[\"model\"]\n",
        "        upsample_factor = strategy[\"upsample\"]\n",
        "        strategy_name = strategy[\"name\"]\n",
        "\n",
        "        try:\n",
        "            face_locations = face_recognition.face_locations(\n",
        "                image,\n",
        "                number_of_times_to_upsample=upsample_factor,\n",
        "                model=model_name\n",
        "            )\n",
        "\n",
        "            if len(face_locations) > 0:\n",
        "                print(f\"   ‚úì Face detected using {strategy_name}.\")\n",
        "                # For simplicity, take the first detected face\n",
        "                best_face_location = face_locations[0]\n",
        "                best_face_encoding = face_recognition.face_encodings(image, [best_face_location])[0]\n",
        "                break # Found a face, no need to try further strategies\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚úó {strategy_name} failed: {e}\")\n",
        "\n",
        "    # If still no face, try image enhancement (contrast)\n",
        "    if best_face_encoding is None:\n",
        "        print(\"   Trying contrast enhancement...\")\n",
        "        pil_image = Image.fromarray(image)\n",
        "        enhancer = ImageEnhance.Contrast(pil_image)\n",
        "        enhanced_image_pil = enhancer.enhance(1.5) # Increase contrast\n",
        "        enhanced_image_np = np.array(enhanced_image_pil)\n",
        "\n",
        "        try:\n",
        "            face_locations = face_recognition.face_locations(enhanced_image_np, model=\"hog\", number_of_times_to_upsample=2)\n",
        "            if len(face_locations) > 0:\n",
        "                print(\"   ‚úì Face detected after contrast enhancement.\")\n",
        "                best_face_location = face_locations[0]\n",
        "                best_face_encoding = face_recognition.face_encodings(enhanced_image_np, [best_face_location])[0]\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚úó Contrast enhancement detection failed: {e}\")\n",
        "\n",
        "    if best_face_encoding is None:\n",
        "        print(f\"‚ö†Ô∏è No face found in {image_path} after all attempts.\")\n",
        "        return None, None, None\n",
        "    else:\n",
        "        top, right, bottom, left = best_face_location\n",
        "        face_image = image[top:bottom, left:right]\n",
        "        print(f\"‚úì Final face detected at position: {best_face_location} in {image_path}\")\n",
        "        return best_face_encoding, best_face_location, face_image"
      ],
      "metadata": {
        "id": "FgPX9bl9s77A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Comparison Function**\n",
        "\n",
        "Face matching algorithm:\n",
        "\n",
        "Calculate Euclidean distance between two face encodings\n",
        "\n",
        "Smaller distance = more similar faces\n",
        "\n",
        "Convert distance to percentage score (0-100%)\n",
        "\n",
        "Use threshold of 0.6 (industry standard)\n",
        "\n",
        "Return match status and similarity score"
      ],
      "metadata": {
        "id": "ElaV_vPPtWTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_two_faces(face_encoding1, face_encoding2):\n",
        "    \"\"\"\n",
        "    Compare two face encodings and calculate similarity\n",
        "\n",
        "    Returns:\n",
        "    - match: True if faces match\n",
        "    - distance: Euclidean distance between encodings\n",
        "    - similarity_score: Percentage similarity (0-100%)\n",
        "    \"\"\"\n",
        "    if face_encoding1 is None or face_encoding2 is None:\n",
        "        return False, None, 0\n",
        "\n",
        "    # Calculate Euclidean distance\n",
        "    # Lower distance = more similar\n",
        "    distance = np.linalg.norm(face_encoding1 - face_encoding2)\n",
        "\n",
        "    # Convert distance to similarity percentage\n",
        "    # Using threshold of 0.6 (common in face recognition)\n",
        "    threshold = 0.6\n",
        "    similarity_score = max(0, 100 * (1 - distance/threshold))\n",
        "\n",
        "    # Determine if it's a match\n",
        "    match = distance < threshold\n",
        "\n",
        "    return match, distance, similarity_score"
      ],
      "metadata": {
        "id": "ab3zu5C5tbGn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualize Face Comparison**\n",
        "\n",
        "Create a visual comparison display showing:\n",
        "\n",
        "Selfie face\n",
        "\n",
        "ID face\n",
        "\n",
        "Similarity score and match result\n",
        "This helps users understand why verification passed or failed."
      ],
      "metadata": {
        "id": "jh7m6mHuttIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_face_comparison(selfie_face, id_face, similarity_score, match_status):\n",
        "    \"\"\"Display side-by-side comparison of faces\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # Display selfie face\n",
        "    axes[0].imshow(selfie_face)\n",
        "    axes[0].set_title(\"üì∏ Your Selfie\", fontsize=14, fontweight='bold')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Display ID face\n",
        "    axes[1].imshow(id_face)\n",
        "    axes[1].set_title(\"üÜî ID Photo\", fontsize=14, fontweight='bold')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Display result\n",
        "    axes[2].text(0.5, 0.7, \"FACE MATCH RESULT\",\n",
        "                 ha='center', va='center', fontsize=16, fontweight='bold')\n",
        "\n",
        "    axes[2].text(0.5, 0.5, f\"Similarity: {similarity_score:.1f}%\",\n",
        "                 ha='center', va='center', fontsize=14)\n",
        "\n",
        "    if match_status:\n",
        "        axes[2].text(0.5, 0.3, \"‚úÖ MATCH CONFIRMED\",\n",
        "                     ha='center', va='center', fontsize=14, color='green', fontweight='bold')\n",
        "    else:\n",
        "        axes[2].text(0.5, 0.3, \"‚ùå NO MATCH\",\n",
        "                     ha='center', va='center', fontsize=14, color='red', fontweight='bold')\n",
        "\n",
        "    # Show threshold info\n",
        "    axes[2].text(0.5, 0.1, f\"Required: >85% similarity\",\n",
        "                 ha='center', va='center', fontsize=10)\n",
        "\n",
        "    axes[2].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ys0__-N1t1rO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OCR Setup for ID Text Extraction**\n",
        "\n",
        "OCR (Optical Character Recognition) setup:\n",
        "\n",
        "Initialize EasyOCR reader for English text\n",
        "\n",
        "First run downloads the model (~100MB)\n",
        "\n",
        "Reader can detect text in images and convert to machine-readable text\n",
        "\n",
        "We'll extract: Name, ID Number, Date of Birth"
      ],
      "metadata": {
        "id": "6bi2xaDpt47I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize OCR reader (this downloads model on first run)\n",
        "print(\"üîÑ Loading OCR engine... (first time may take a minute)\")\n",
        "ocr_reader = easyocr.Reader(['en'])\n",
        "print(\"‚úÖ OCR engine ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgXC8guduKdv",
        "outputId": "c24497bd-5a3d-4233-c25d-6009ab6f4df3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading OCR engine... (first time may take a minute)\n",
            "‚úÖ OCR engine ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Text from ID**\n",
        "\n",
        "Text extraction process:\n",
        "\n",
        "Use EasyOCR to read all text in ID image\n",
        "\n",
        "Apply regex patterns to find specific information:\n",
        "\n",
        "Name: Capitalized words (2-3 parts)\n",
        "\n",
        "ID Number: 6-10 digits or alphanumeric\n",
        "\n",
        "Date of Birth: Various date formats\n",
        "\n",
        "Return structured dictionary of extracted data"
      ],
      "metadata": {
        "id": "ShqEYR05uaVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_id_information(image_path, reader):\n",
        "    \"\"\"Extract name, ID number, and DOB from ID image\"\"\"\n",
        "\n",
        "    # Read text from image using OCR\n",
        "    print(f\"üîç Reading text from {image_path}...\")\n",
        "    ocr_results = reader.readtext(image_path)\n",
        "\n",
        "    # Combine all detected text\n",
        "    all_text = ' '.join([result[1] for result in ocr_results])\n",
        "    print(f\"üìù Raw text found: {all_text[:100]}...\")\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    extracted_data = {\n",
        "        'full_name': None,\n",
        "        'id_number': None,\n",
        "        'date_of_birth': None,\n",
        "        'raw_text': all_text\n",
        "    }\n",
        "\n",
        "    # PATTERN 1: Find Name (capitalized words, 2-3 parts)\n",
        "    name_pattern = r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+){1,2})\\b'\n",
        "    name_match = re.search(name_pattern, all_text)\n",
        "    if name_match:\n",
        "        extracted_data['full_name'] = name_match.group(1)\n",
        "        print(f\"‚úì Found name: {extracted_data['full_name']}\")\n",
        "\n",
        "    # PATTERN 2: Find ID Number (common formats)\n",
        "    id_patterns = [\n",
        "        r'\\b\\d{8}\\b',  # 8 digits (Kenyan ID)\n",
        "        r'\\b\\d{6,10}\\b',  # 6-10 digits\n",
        "        r'[A-Z0-9]{6,12}',  # Alphanumeric\n",
        "        r'ID[:\\s]\\s*([A-Z0-9]+)',  # \"ID: ABC123\"\n",
        "    ]\n",
        "\n",
        "    for pattern in id_patterns:\n",
        "        id_match = re.search(pattern, all_text)\n",
        "        if id_match and not extracted_data['id_number']:\n",
        "            extracted_data['id_number'] = id_match.group()\n",
        "            print(f\"‚úì Found ID: {extracted_data['id_number']}\")\n",
        "            break\n",
        "\n",
        "    # PATTERN 3: Find Date of Birth\n",
        "    dob_patterns = [\n",
        "        r'\\b\\d{2}/\\d{2}/\\d{4}\\b',  # DD/MM/YYYY\n",
        "        r'\\b\\d{2}-\\d{2}-\\d{4}\\b',  # DD-MM-YYYY\n",
        "        r'DOB[:\\s]\\s*(\\d{2}[\\/\\-]\\d{2}[\\/\\-]\\d{4})',  # \"DOB: 01/01/1990\"\n",
        "        r'Birth[:\\s]\\s*(\\d{2}[\\/\\-]\\d{2}[\\/\\-]\\d{4})',  # \"Birth: 01/01/1990\"\n",
        "    ]\n",
        "\n",
        "    for pattern in dob_patterns:\n",
        "        dob_match = re.search(pattern, all_text)\n",
        "        if dob_match and not extracted_data['date_of_birth']:\n",
        "            extracted_data['date_of_birth'] = dob_match.group()\n",
        "            print(f\"‚úì Found DOB: {extracted_data['date_of_birth']}\")\n",
        "            break\n",
        "\n",
        "    return extracted_data"
      ],
      "metadata": {
        "id": "0sjz_e42uklI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Extracted Information**\n",
        "\n",
        "Show extracted data in user-friendly format:\n",
        "\n",
        "Display each extracted field\n",
        "\n",
        "Show confidence level based on what was found\n",
        "\n",
        "Format for easy reading"
      ],
      "metadata": {
        "id": "wTz_-sWGupBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_extracted_info(info_dict):\n",
        "    \"\"\"Display extracted information in readable format\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üìÑ EXTRACTED ID INFORMATION\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    print(f\"\\nüë§ Name: {info_dict['full_name'] or 'Not found'}\")\n",
        "    print(f\"üÜî ID Number: {info_dict['id_number'] or 'Not found'}\")\n",
        "    print(f\"üéÇ Date of Birth: {info_dict['date_of_birth'] or 'Not found'}\")\n",
        "\n",
        "    # Calculate extraction confidence\n",
        "    fields_found = sum(1 for key in ['full_name', 'id_number', 'date_of_birth']\n",
        "                      if info_dict[key])\n",
        "\n",
        "    print(f\"\\nüìä Extraction Confidence: {fields_found}/3 fields found\")\n",
        "\n",
        "    if fields_found == 3:\n",
        "        print(\"‚úÖ All required information extracted successfully!\")\n",
        "    elif fields_found >= 2:\n",
        "        print(\"‚ö†Ô∏è Most information extracted (check missing fields)\")\n",
        "    else:\n",
        "        print(\"‚ùå Poor extraction - check image quality\")\n",
        "\n",
        "    print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "XRzkrrjwu3Nl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complete Verification Function**\n",
        "\n",
        "Main verification pipeline that combines:\n",
        "\n",
        "Face detection from both images\n",
        "\n",
        "Face similarity calculation\n",
        "\n",
        "ID text extraction\n",
        "\n",
        "Final decision based on >85% similarity threshold\n",
        "Returns comprehensive verification result"
      ],
      "metadata": {
        "id": "I6F4oyGjvCwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_identity(selfie_path, id_front_path, id_back_path=None):\n",
        "    \"\"\"\n",
        "    Complete identity verification process\n",
        "\n",
        "    Returns dictionary with:\n",
        "    - verification_status: PASSED/FAILED\n",
        "    - similarity_score: Face match percentage\n",
        "    - extracted_info: ID data\n",
        "    - timestamp: When verification happened\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üîê STARTING IDENTITY VERIFICATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # STEP 1: Detect faces\n",
        "    print(\"\\n1Ô∏è‚É£ DETECTING FACES...\")\n",
        "    # The detect_face_in_image function now handles multiple strategies internally\n",
        "    selfie_encoding, _, selfie_face = detect_face_in_image(selfie_path)\n",
        "    id_encoding, _, id_face = detect_face_in_image(id_front_path)\n",
        "\n",
        "    if selfie_encoding is None or id_encoding is None:\n",
        "        print(\"‚ùå Face detection failed for one or both images. Please retry with clearer images.\")\n",
        "        return None\n",
        "\n",
        "    # STEP 2: Compare faces\n",
        "    print(\"\\n2Ô∏è‚É£ COMPARING FACES...\")\n",
        "    match, distance, similarity_score = compare_two_faces(selfie_encoding, id_encoding)\n",
        "\n",
        "    print(f\"   Face Distance: {distance:.4f}\")\n",
        "    print(f\"   Similarity Score: {similarity_score:.1f}%\")\n",
        "    print(f\"   Match Found: {'Yes' if match else 'No'}\")\n",
        "\n",
        "    # STEP 3: Extract ID information\n",
        "    print(\"\\n3Ô∏è‚É£ EXTRACTING ID TEXT...\")\n",
        "    id_info = extract_id_information(id_front_path, ocr_reader)\n",
        "\n",
        "    # Extract from back if provided\n",
        "    if id_back_path and os.path.exists(id_back_path):\n",
        "        print(\"   Extracting from ID back...\")\n",
        "        back_info = extract_id_information(id_back_path, ocr_reader)\n",
        "\n",
        "        # Merge info (use front as priority)\n",
        "        for key in ['full_name', 'id_number', 'date_of_birth']:\n",
        "            if not id_info[key] and back_info[key]:\n",
        "                id_info[key] = back_info[key]\n",
        "\n",
        "    # STEP 4: Display results\n",
        "    print(\"\\n4Ô∏è‚É£ DISPLAYING RESULTS...\")\n",
        "    display_face_comparison(selfie_face, id_face, similarity_score, match)\n",
        "    show_extracted_info(id_info)\n",
        "\n",
        "    # STEP 5: Make final decision\n",
        "    print(\"\\n5Ô∏è‚É£ FINAL VERIFICATION DECISION\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    verification_passed = similarity_score > 85\n",
        "\n",
        "    if verification_passed:\n",
        "        print(\"‚úÖ VERIFICATION PASSED!\")\n",
        "        print(f\"   You are verified as: {id_info.get('full_name', 'Unknown')}\")\n",
        "        status = \"PASSED\"\n",
        "    else:\n",
        "        print(\"‚ùå VERIFICATION FAILED\")\n",
        "        print(f\"   Similarity score ({similarity_score:.1f}%) below 85% threshold\")\n",
        "        status = \"FAILED\"\n",
        "\n",
        "    # Compile results\n",
        "    verification_result = {\n",
        "        'verification_status': status,\n",
        "        'face_similarity_score': float(similarity_score),\n",
        "        'face_match': bool(match),\n",
        "        'extracted_info': id_info,\n",
        "        'verification_timestamp': datetime.now().isoformat(),\n",
        "        'required_threshold': 85.0\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ VERIFICATION COMPLETE\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    return verification_result"
      ],
      "metadata": {
        "id": "Iy9J5jlxvJVX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Results Function**\n",
        "\n",
        "Save verification results for:\n",
        "\n",
        "Future reference\n",
        "\n",
        "Integration with Phase 2\n",
        "\n",
        "Audit trail\n",
        "Saves as both JSON (detailed) and CSV (summary)"
      ],
      "metadata": {
        "id": "KBcJTLoovPlS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_verification_results(results, output_dir='verification_results'):\n",
        "    \"\"\"Save verification results to files\"\"\"\n",
        "\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate unique ID\n",
        "    user_id = f\"user_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "    # Save as JSON (full details)\n",
        "    json_filename = f\"{output_dir}/{user_id}_full_results.json\"\n",
        "    with open(json_filename, 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    # Save as CSV (summary)\n",
        "    csv_data = {\n",
        "        'user_id': user_id,\n",
        "        'timestamp': results['verification_timestamp'],\n",
        "        'status': results['verification_status'],\n",
        "        'similarity_score': results['face_similarity_score'],\n",
        "        'name': results['extracted_info'].get('full_name', ''),\n",
        "        'id_number': results['extracted_info'].get('id_number', ''),\n",
        "        'dob': results['extracted_info'].get('date_of_birth', '')\n",
        "    }\n",
        "\n",
        "    csv_filename = f\"{output_dir}/{user_id}_summary.csv\"\n",
        "    df = pd.DataFrame([csv_data])\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "\n",
        "    print(f\"\\nüíæ Results saved:\")\n",
        "    print(f\"   üìÑ Full details: {json_filename}\")\n",
        "    print(f\"   üìä Summary: {csv_filename}\")\n",
        "\n",
        "    # Also save data for next phase\n",
        "    next_phase_data = {\n",
        "        'user_id': user_id,\n",
        "        'verified_name': csv_data['name'],\n",
        "        'verified_id_number': csv_data['id_number'],\n",
        "        'verification_score': csv_data['similarity_score'],\n",
        "        'verification_time': csv_data['timestamp']\n",
        "    }\n",
        "\n",
        "    with open('next_phase_data.json', 'w') as f:\n",
        "        json.dump(next_phase_data, f, indent=2)\n",
        "\n",
        "    print(f\"   üîó Next phase data: next_phase_data.json\")\n",
        "\n",
        "    return json_filename, csv_filename"
      ],
      "metadata": {
        "id": "AGK5tu1avUoJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Main Execution Function**\n",
        "\n",
        "Complete workflow that users will run:\n",
        "\n",
        "Upload images\n",
        "\n",
        "Run verification\n",
        "\n",
        "Save results\n",
        "\n",
        "Prepare for next phase\n",
        "This is the function users should call"
      ],
      "metadata": {
        "id": "oGpRJbgVvZ4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_complete_verification():\n",
        "    \"\"\"Main function to run the entire verification process\"\"\"\n",
        "\n",
        "    print(\"üëã WELCOME TO IDENTITY VERIFICATION SYSTEM\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Step 1: Upload images\n",
        "    print(\"\\nüì§ STEP 1: Using Pre-Uploaded Images\")\n",
        "    selfie_path, id_front_path, id_back_path = upload_id_images()\n",
        "\n",
        "    if selfie_path is None or id_front_path is None:\n",
        "        print(\"‚ùå Image files missing. Please ensure 'selfie.jpg' and 'id_front.jpg' are uploaded and correctly named.\")\n",
        "        return None\n",
        "\n",
        "    # Step 2: Run verification\n",
        "    print(\"\\nüîç STEP 2: Verifying Identity...\")\n",
        "    results = verify_identity(selfie_path, id_front_path, id_back_path)\n",
        "\n",
        "    if results is None:\n",
        "        print(\"‚ùå Verification failed. Please try again.\")\n",
        "        return None\n",
        "\n",
        "    # Step 3: Save results\n",
        "    print(\"\\nüíæ STEP 3: Saving Results...\")\n",
        "    json_file, csv_file = save_verification_results(results)\n",
        "\n",
        "    # Step 4: Next steps\n",
        "    print(\"\\nüöÄ STEP 4: Next Steps\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    if results['verification_status'] == 'PASSED':\n",
        "        print(\"‚úÖ Ready for Phase 2: Financial Data Collection\")\n",
        "        print(f\"   User: {results['extracted_info'].get('full_name', 'Unknown')}\")\n",
        "        print(f\"   Score: {results['face_similarity_score']:.1f}%\")\n",
        "        print(\"\\nüìã Next phase will collect:\")\n",
        "        print(\"   ‚Ä¢ M-Pesa transaction history\")\n",
        "        print(\"   ‚Ä¢ Airtime usage data\")\n",
        "        print(\"   ‚Ä¢ Financial behavior analysis\")\n",
        "    else:\n",
        "        print(\"‚ùå Cannot proceed to Phase 2\")\n",
        "        print(\"   Please retry verification with:\")\n",
        "        print(\"   1. Better lighting\")\n",
        "        print(\"   2. Clearer ID photo\")\n",
        "        print(\"   3. Straight-facing selfie\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ============================================\n",
        "# üöÄ RUN THE COMPLETE VERIFICATION\n",
        "# ============================================\n",
        "print(\"Ready to run identity verification!\")\n",
        "verification_results = run_complete_verification()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55NEvdCWveRq",
        "outputId": "3eff594f-f027-4e3e-acea-1bcf98447bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to run identity verification!\n",
            "üëã WELCOME TO IDENTITY VERIFICATION SYSTEM\n",
            "==================================================\n",
            "\n",
            "üì§ STEP 1: Using Pre-Uploaded Images\n",
            "üì± LOOKING FOR YOUR IMAGES (Please ensure they are named selfie.jpg, id_front.jpg, and optionally id_back.jpg)\n",
            "----------------------------------------\n",
            "‚úì Found: selfie.jpg\n",
            "‚úì Found: id_front.jpg\n",
            "‚úì Found: id_back.jpg\n",
            "\n",
            "üîç STEP 2: Verifying Identity...\n",
            "\n",
            "============================================================\n",
            "üîê STARTING IDENTITY VERIFICATION\n",
            "============================================================\n",
            "\n",
            "1Ô∏è‚É£ DETECTING FACES...\n",
            "üîÑ Attempting robust face detection for selfie.jpg...\n",
            "‚úì Fixed orientation for selfie.jpg, saved to selfie_fixed.jpg\n",
            "   ‚úì Face detected using HOG (upsample 2x).\n",
            "‚úì Final face detected at position: (640, 1412, 1634, 419) in selfie.jpg\n",
            "üîÑ Attempting robust face detection for id_front.jpg...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22545e54"
      },
      "source": [
        "### Reviewing the problematic Selfie Image\n",
        "\n",
        "Here is the selfie image that caused the 'No face found' error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05815753"
      },
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the selfie image that failed detection\n",
        "selfie_fail_path = 'selfie.jpg'\n",
        "\n",
        "if os.path.exists(selfie_fail_path):\n",
        "    img = Image.open(selfie_fail_path)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Selfie Image (Failed Face Detection)')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Error: The file {selfie_fail_path} was not found.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823802ff"
      },
      "source": [
        "### Why Face Detection Might Fail\n",
        "\n",
        "Face detection models, while powerful, can be sensitive to various factors. If the system reported 'No face found' even when you believe your face was clearly visible, here are some common reasons:\n",
        "\n",
        "*   **Poor Lighting:** Insufficient or harsh lighting can obscure facial features.\n",
        "*   **Angles and Pose:** Extreme angles, looking significantly away from the camera, or having part of your face covered can hinder detection.\n",
        "*   **Obstructions:** Hair, glasses (especially reflective ones), hats, masks, or hands covering parts of the face can make detection difficult.\n",
        "*   **Image Resolution and Quality:** Low-resolution images, blurry photos, or highly compressed images may lack the detail needed for accurate detection.\n",
        "*   **Distance from Camera:** Being too far or too close to the camera can affect how clearly facial features are captured.\n",
        "*   **Background Clutter:** A busy or complex background might confuse the detection algorithm, making it harder to isolate the face.\n",
        "\n",
        "To improve detection, please ensure your selfie:\n",
        "\n",
        "1.  **Has good, even lighting.**\n",
        "2.  **Shows your face clearly, looking straight at the camera.**\n",
        "3.  **Is free from obstructions (hair, accessories, etc.).**\n",
        "4.  **Is sharp and of reasonable quality.**\n",
        "\n",
        "Please retry the verification process with an image that meets these guidelines."
      ]
    }
  ]
}